{"cells":[{"cell_type":"markdown","metadata":{"id":"W8XQeIF6rBI6"},"source":["# Lab session 2: Language modeling"]},{"cell_type":"markdown","metadata":{"id":"-qGoVr7SrBI8"},"source":["This lab covers classical and neural language models as seen in the theory lectures. \n","\n","General instructions:\n","- Complete the code where needed\n","- Provide answers to questions only in the cell where indicated\n","- **Do not alter the evaluation cells** (`## evaluation`) in any way as they are needed for the partly automated evaluation process\n","\n","We advise you to run this notebook on Google Colab, otherwise we cannot guarantee identical versioning of the packages used in this lab (which is necessary for the automated checks). This also allows you to run your code on a GPU, which is especially relevant for the second part (Deep Learning Based Language Models). "]},{"cell_type":"markdown","metadata":{"id":"Ppr_iMCj2bi7"},"source":["## **How AI can write a paper!**\n","\n","We shall train our language model on a corpus of scientific articles and see if we can generate a new one!\n","\n","<img src=\"https://media1.tenor.com/images/073dfe5d68e2490903aa51ae0ac633de/tenor.gif?itemid=3536848\" alt=\"img\" width=\"512px\"/>\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"92oj5l862bi-","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703602744,"user_tz":-120,"elapsed":1369,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["# import necessary packages\n","\n","from __future__ import division\n","from __future__ import unicode_literals\n","\n","import random as rand\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VLOk8it2UPwy","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703605932,"user_tz":-120,"elapsed":81,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["# for reproducability\n","SEED = 42\n","np.random.seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"2cFtNG-Q2bjJ"},"source":["## **Data exploration**\n","\n","Lets download and look into the data:\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"T7oF8ejH_t2k","outputId":"b79205e3-f706-409f-8cd5-22661249f054","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703626710,"user_tz":-120,"elapsed":5479,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-11 19:00:21--  https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/dl/99az9n1b57qkd9j/arxivData.json.tar.gz [following]\n","--2022-04-11 19:00:21--  https://www.dropbox.com/s/dl/99az9n1b57qkd9j/arxivData.json.tar.gz\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc4fb10b0f9e487247256a05733e.dl.dropboxusercontent.com/cd/0/get/BjNII3xhTMmyQ5BE3h-wBxViX6Xc8h3p6ZMGnOCRUQFUPUKsftKy2oSsOr9I2OUHxhZIDR0Xqd_GooIOjlm_aiTembbZVDHrP9BvV1b8C4bbrsLaL00y2xCNiBDvzaMq_Nn4ValHTzXxx9ZF9gnGNY3HzLjsuvJ5DkZ1ZTFewe6FOw/file?dl=1# [following]\n","--2022-04-11 19:00:24--  https://uc4fb10b0f9e487247256a05733e.dl.dropboxusercontent.com/cd/0/get/BjNII3xhTMmyQ5BE3h-wBxViX6Xc8h3p6ZMGnOCRUQFUPUKsftKy2oSsOr9I2OUHxhZIDR0Xqd_GooIOjlm_aiTembbZVDHrP9BvV1b8C4bbrsLaL00y2xCNiBDvzaMq_Nn4ValHTzXxx9ZF9gnGNY3HzLjsuvJ5DkZ1ZTFewe6FOw/file?dl=1\n","Resolving uc4fb10b0f9e487247256a05733e.dl.dropboxusercontent.com (uc4fb10b0f9e487247256a05733e.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc4fb10b0f9e487247256a05733e.dl.dropboxusercontent.com (uc4fb10b0f9e487247256a05733e.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 18933283 (18M) [application/binary]\n","Saving to: ‘arxivData.json.tar.gz’\n","\n","arxivData.json.tar. 100%[===================>]  18.06M  53.9MB/s    in 0.3s    \n","\n","2022-04-11 19:00:25 (53.9 MB/s) - ‘arxivData.json.tar.gz’ saved [18933283/18933283]\n","\n","arxivData.json\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                  author  day            id  \\\n","857    [{'name': 'A. N. Gorban'}, {'name': 'A. Y. Zin...    2   0809.0490v2   \n","144    [{'name': 'Behnam Neyshabur'}, {'name': 'Ryota...   27  1503.00036v2   \n","22961  [{'name': 'Maria De-Arteaga'}, {'name': 'Willi...   27  1711.09522v2   \n","19448      [{'name': 'J. Keppens'}, {'name': 'Q. Shen'}]   30   1107.0035v1   \n","2331   [{'name': 'Kevin T. Kelly'}, {'name': 'Conor M...   15   1203.3488v1   \n","\n","                                                    link  month  \\\n","857    [{'rel': 'related', 'href': 'http://dx.doi.org...      9   \n","144    [{'rel': 'alternate', 'href': 'http://arxiv.or...      2   \n","22961  [{'rel': 'alternate', 'href': 'http://arxiv.or...     11   \n","19448  [{'rel': 'related', 'href': 'http://dx.doi.org...      6   \n","2331   [{'rel': 'alternate', 'href': 'http://arxiv.or...      3   \n","\n","                                                 summary  \\\n","857    In many physical, statistical, biological and ...   \n","144    We investigate the capacity, convexity and cha...   \n","22961  This is the Proceedings of NIPS 2017 Workshop ...   \n","19448  The predominant knowledge-based approach to au...   \n","2331   Over the past two decades, several consistent ...   \n","\n","                                                     tag  \\\n","857    [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n","144    [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n","22961  [{'term': 'stat.ML', 'scheme': 'http://arxiv.o...   \n","19448  [{'term': 'cs.AI', 'scheme': 'http://arxiv.org...   \n","2331   [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n","\n","                                                   title  year  \n","857                       Principal Graphs and Manifolds  2008  \n","144       Norm-Based Capacity Control in Neural Networks  2015  \n","22961  Proceedings of NIPS 2017 Workshop on Machine L...  2017  \n","19448  Compositional Model Repositories via Dynamic C...  2011  \n","2331   Causal Conclusions that Flip Repeatedly and Th...  2012  "],"text/html":["\n","  <div id=\"df-9a625a45-8037-4422-b64c-e24c7949f988\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>day</th>\n","      <th>id</th>\n","      <th>link</th>\n","      <th>month</th>\n","      <th>summary</th>\n","      <th>tag</th>\n","      <th>title</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>857</th>\n","      <td>[{'name': 'A. N. Gorban'}, {'name': 'A. Y. Zin...</td>\n","      <td>2</td>\n","      <td>0809.0490v2</td>\n","      <td>[{'rel': 'related', 'href': 'http://dx.doi.org...</td>\n","      <td>9</td>\n","      <td>In many physical, statistical, biological and ...</td>\n","      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n","      <td>Principal Graphs and Manifolds</td>\n","      <td>2008</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>[{'name': 'Behnam Neyshabur'}, {'name': 'Ryota...</td>\n","      <td>27</td>\n","      <td>1503.00036v2</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>2</td>\n","      <td>We investigate the capacity, convexity and cha...</td>\n","      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n","      <td>Norm-Based Capacity Control in Neural Networks</td>\n","      <td>2015</td>\n","    </tr>\n","    <tr>\n","      <th>22961</th>\n","      <td>[{'name': 'Maria De-Arteaga'}, {'name': 'Willi...</td>\n","      <td>27</td>\n","      <td>1711.09522v2</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>11</td>\n","      <td>This is the Proceedings of NIPS 2017 Workshop ...</td>\n","      <td>[{'term': 'stat.ML', 'scheme': 'http://arxiv.o...</td>\n","      <td>Proceedings of NIPS 2017 Workshop on Machine L...</td>\n","      <td>2017</td>\n","    </tr>\n","    <tr>\n","      <th>19448</th>\n","      <td>[{'name': 'J. Keppens'}, {'name': 'Q. Shen'}]</td>\n","      <td>30</td>\n","      <td>1107.0035v1</td>\n","      <td>[{'rel': 'related', 'href': 'http://dx.doi.org...</td>\n","      <td>6</td>\n","      <td>The predominant knowledge-based approach to au...</td>\n","      <td>[{'term': 'cs.AI', 'scheme': 'http://arxiv.org...</td>\n","      <td>Compositional Model Repositories via Dynamic C...</td>\n","      <td>2011</td>\n","    </tr>\n","    <tr>\n","      <th>2331</th>\n","      <td>[{'name': 'Kevin T. Kelly'}, {'name': 'Conor M...</td>\n","      <td>15</td>\n","      <td>1203.3488v1</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>3</td>\n","      <td>Over the past two decades, several consistent ...</td>\n","      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n","      <td>Causal Conclusions that Flip Repeatedly and Th...</td>\n","      <td>2012</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a625a45-8037-4422-b64c-e24c7949f988')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9a625a45-8037-4422-b64c-e24c7949f988 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9a625a45-8037-4422-b64c-e24c7949f988');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["!wget \"https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\" -O arxivData.json.tar.gz\n","!tar -xvzf arxivData.json.tar.gz\n","data = pd.read_json(\"./arxivData.json\")\n","data.sample(n=5)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YY8udsOVSh_F","outputId":"647c4e1e-3337-4039-ca15-e715e9dab1ab","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703637651,"user_tz":-120,"elapsed":568,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Differential Contrastive Divergence ; This paper has been retracted.',\n"," 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n"," 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"]},"metadata":{},"execution_count":4}],"source":["# Assemble lines: concatenate title and description\n","lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'], axis=1).tolist()\n","\n","# Sample the first 3 lines...\n","sorted(lines, key=len)[:3]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbXJxSil2bjM","outputId":"28c5334f-35cc-4457-e018-debc9aa5f783","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703644449,"user_tz":-120,"elapsed":3145,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['differential contrastive divergence ; this paper has been retracted .',\n"," 'what does artificial life tell us about death ? ; short philosophical essay',\n"," 'p = np ; we claim to resolve the p =? np problem via a formal argument for p = np .']"]},"metadata":{},"execution_count":5}],"source":["# Convert lines into strings of space-separated tokens\n","#! pip install nltk  # install if not yet installed\n","\n","from nltk.tokenize import WordPunctTokenizer\n","tknzr = WordPunctTokenizer()\n","lines = [tknzr.tokenize(sent.lower()) for sent in lines]\n","lines = [' '.join(sent) for sent in lines]\n","\n","sorted(lines, key=len)[:3]"]},{"cell_type":"markdown","metadata":{"id":"6DRT4A8q2bjP"},"source":["## **N-Gram Language Model**\n","\n","A language model is a probabilistic model that estimates text probability: the joint probability of all tokens $w_t$ in text $X$: $P(X) = P(w_1, \\dots, w_T)$.\n","\n","It can do so by following the chain rule:\n","$$P(w_1, \\dots, w_T) = P(w_1)P(w_2 \\mid w_1)\\dots P(w_T \\mid w_1, \\dots, w_{T-1}).$$ \n","\n","The problem with such approach is that the final term $P(w_T \\mid w_1, \\dots, w_{T-1})$ depends on $n-1$ previous words. This probability is impractical to estimate for long texts, e.g. $T = 1000$.\n","\n","One popular approximation is to assume that the next word only depends on a finite amount of previous words:\n","\n","$$P(w_t \\mid w_1, \\dots, w_{t - 1}) = P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1})$$\n","\n","Such a model is called an __n-gram language model__ where n is a parameter. For example, in a 3-gram language model, each word only depends on the 2 previous words. \n","\n","$$\n","    P(w_1, \\dots, w_n) = \\prod_t P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1}).\n","$$\n","\n","You might also come across this approximation under the name of the _n-th order markov assumption_.\n","\n","The first stage in building such a model is counting all word occurences given the $n-1$ previous words:"]},{"cell_type":"markdown","metadata":{"id":"bWf1sSBJ6FxD"},"source":["### Building the model"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nWJiczkr2bjR","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703760057,"user_tz":-120,"elapsed":315,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["from collections import defaultdict, Counter\n","\n","# special tokens: \n","# - UNK represents absent tokens, \n","# - EOS is a special token after the end of sequence\n","\n","UNK, EOS = \"_UNK_\", \"_EOS_\"\n","\n","def count_ngrams(lines, n):\n","    \"\"\"\n","    Count how many times each word occurred after (n - 1) previous words\n","    :param lines: an iterable of strings with space-separated tokens\n","    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2, ...}}\n","\n","    When building counts, please consider the following two edge cases\n","    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n","      empty prefix: \"\" -> (UNK, UNK)\n","      short prefix: \"the\" -> (UNK, the)\n","      long prefix: \"the new approach\" -> (new, approach)\n","    - you should add a special token, EOS, at the end of each sequence\n","      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n","      count the probability of this token just like all others.\n","    \"\"\"\n","    \n","    counts = defaultdict(Counter)\n","    n_gram_dict = {}\n","    n_gram_list = []    \n","    # counts[(word 1, word 2 ... word n-1)][word n] \n","    #    = how many times word n occurred after (word 1 ... word n-1)\n","    \n","    for sent in lines:\n","        sent = sent.split() + [EOS]\n","        for i, word in enumerate(sent):\n","            ############### for student ################\n","            if i < n-1:\n","                prefix_tuple = tuple([UNK]*(n-1-i) + sent[:i])\n","                n_gram_list.append((prefix_tuple, word))\n","            else:\n","                prefix_tuple = tuple(sent[i-n+1:i])\n","                n_gram_list.append((prefix_tuple, word))\n","    # a = Counter(n_gram_list)\n","    # for key, value in a.items():\n","    #     counts[key[0]] = {key[1]:value}\n","\n","    for k_v in n_gram_list:\n","\t      k, v = k_v\n","\t      counts.setdefault(k, []).append(v)\n","    for k, v in counts.items():\n","        counts[k] = Counter(v)\n","            ############################################\n","\n","    return counts\n","\n","\n","# dummy_lines = sorted(lines, key=len)[:100]\n","# dummy_counts = count_ngrams(dummy_lines, n=3)\n","# print(dummy_counts['author', '.']['_EOS_'])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQJIOfRf2bjU","outputId":"498eac94-1928-4489-9f69-073790938365","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703772517,"user_tz":-120,"elapsed":269,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["well done!\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","dummy_lines = sorted(lines, key=len)[:100]\n","dummy_counts = count_ngrams(dummy_lines, n=3)\n","assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n","assert dummy_counts['author', '.']['_EOS_'] == 1\n","assert dummy_counts['p', '=']['np'] == 2\n","# assert len(dummy_counts[('_UNK_', '_UNK_')]) == 78\n","assert dummy_counts['_UNK_', 'a']['note'] == 3\n","\n","print('well done!')"]},{"cell_type":"markdown","metadata":{"id":"j1PER9Ue2bjX"},"source":["Once we can count N-grams, we can build a probabilistic language model.\n","The simplest way to compute probabilities is in proporiton to counts:\n","\n","$$ P(w | \\textit{prefix}) = { \\textit{Count}(\\textit{prefix}, w) \\over \\sum_{w' \\in \\textit{Vocab}} \\textit{Count}(\\textit{prefix}, w') } $$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGj4zemN2bjY","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649193605305,"user_tz":-120,"elapsed":5,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cbb0f3a8-3af2-40ea-fc8d-dab61202dc27"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.46\n"]}],"source":["class NGramLanguageModel:    \n","    def __init__(self, lines, n):\n","        \"\"\" \n","        Train a simple count-based language model: \n","        compute probabilities P(w | prefix) given n-gram counts\n","        \n","        :param n: computes probability of next token given (n - 1) previous words\n","        :param lines: an iterable of strings with space-separated tokens\n","        \"\"\"\n","        assert n >= 1\n","        self.n = n\n","    \n","        counts = count_ngrams(lines, self.n)\n","        self.probs = defaultdict(Counter)\n","        \n","        # compute token probabilities (self.probs), given the counts computed above\n","        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n","        ############### for student ################\n","        for key, value in counts.items():\n","            sumup = sum([v for v in value.values()])\n","            for k, v in value.items():\n","                value[k] = v/sumup\n","            self.probs[key] = value   \n","\n","\n","        ############################################\n","\n","    def get_possible_next_tokens(self, prefix):\n","        \"\"\"\n","        :param prefix: string with space-separated prefix tokens\n","        :returns: a dictionary {token : its probability} for all tokens with positive probabilities\n","        \"\"\"\n","        prefix = prefix.split()\n","        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n","        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n","        return self.probs[tuple(prefix)]\n","    \n","    def get_next_token_prob(self, prefix, next_token):\n","        \"\"\"\n","        :param prefix: string with space-separated prefix tokens\n","        :param next_token: the next token to predict probability for\n","        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n","        \"\"\"\n","        return self.get_possible_next_tokens(prefix).get(next_token, 0)\n","\n","\n","dummy_lm = NGramLanguageModel(dummy_lines, n=2)\n","p_initial = dummy_lm.get_next_token_prob('this','paper')\n","print(p_initial)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gfbC9yas2bjb"},"source":["Let's test it!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47vBFod12bjc","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649187856346,"user_tz":-120,"elapsed":256,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"b74d7e96-e826-46d3-fc65-2e2b7d01b696"},"outputs":[{"output_type":"stream","name":"stdout","text":["Good job!\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n","\n","p_initial = dummy_lm.get_possible_next_tokens('') # '' -> ['_UNK_', '_UNK_']\n","assert np.allclose(p_initial['learning'], 0.02)\n","assert np.allclose(p_initial['a'], 0.13)\n","assert np.allclose(p_initial.get('meow', 0), 0)\n","assert np.allclose(sum(p_initial.values()), 1)\n","\n","p_a = dummy_lm.get_possible_next_tokens('a') # '' -> ['_UNK_', 'a']\n","assert np.allclose(p_a['machine'], 0.15384615)\n","assert np.allclose(p_a['note'], 0.23076923)\n","assert np.allclose(p_a.get('the', 0), 0)\n","assert np.allclose(sum(p_a.values()), 1)\n","\n","assert np.allclose(dummy_lm.get_possible_next_tokens('a note')['on'], 1)\n","assert dummy_lm.get_possible_next_tokens('a machine') == \\\n","    dummy_lm.get_possible_next_tokens(\"there have always been ghosts in a machine\"), \\\n","    \"your 3-gram model should only depend on 2 previous words\"\n","\n","print(\"Good job!\")"]},{"cell_type":"markdown","metadata":{"id":"K6DqTkI32bjf"},"source":["Now that you've got a working n-gram language model, let's see what sequences it can generate. But first, let's train it on the whole dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-c5_g1km2bjg","pycharm":{"is_executing":true}},"outputs":[],"source":["lm = NGramLanguageModel(lines, n=3)"]},{"cell_type":"markdown","metadata":{"id":"PSUlkZLx2bjj"},"source":["The process of generating sequences is... well, it's sequential. You maintain a list of tokens and iteratively add the next token by sampling from the probabilities over the vocabulary at each point in the sequence.\n","\n","$ X = [] $\n","\n","__forever:__\n","* $w_{next} \\sim P(w_{next} | X)$\n","* $X = concat(X, w_{next})$\n","\n","\n","Instead of sampling with probabilities, one can also take the most likely token, sample from among the top-K most likely tokens, or sample with a certain *temperature*. In the latter case (temperature), one samples from\n","\n","$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{w'} P(w' | X) ^ {1 / \\tau}}$$\n","\n","Where $\\tau > 0$ is the model temperature. If $\\tau << 1$, more likely tokens will be sampled with even higher probability while less likely tokens will vanish. For sampling from a given probability distribution, the function `nn.random.choice` can be used."]},{"cell_type":"markdown","source":["关于Normalization:  \n","\n","当时想到这个词其实是根据这个公式,因为我觉得这个分式除法等同于做了一个normalization:\n","$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{w'} P(w' | X) ^ {1 / \\tau} }$$  \n","\n","Step1:   \n","\n"," $$w_{next} \\sim P(w_{next} | X)$$\n"," \n","首先我们已知对于文本预测问题，因为如果给出 $P(w_{next} | X)$ 这个离散分布 (注意理解其统计学含义：表示已知context(即X)之后，下面一个token为$\\omega_{next}$的概率)。因此，若我们像预测下一个token是什么，我们可以直接对其进行采样(i.e., sample)，得到下一个token的可能的值。(这个先理解一下)\n","\n","Step2:   \n","\n","$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{w'} P(w' | X) ^ {1 / \\tau} }$$ \n","那么这个地方提到了，(见上3.),除了直接通过$w_{next} \\sim P(w_{next} | X)$ 进行采样，我们也可以引入一个temperature parameter $\\tau$，从而在上面这个(通过引入τ)改变了的分布里面进行采样。\n","\n","我最先看到这个分式的时候很疑惑,原因有2点: 1. 因为给一个概率加上$1/\\tau$之后，某种意义上它就不具备以前的统计学特性了: 也就是说，如果我们用$P(w_{next} | X)$表示已知context(即$X$)之后，下面一个token为$\\omega_{next}$的概率的话，那么$P(w_{next} | X) ^ {1 / \\tau}$ 这种在概率之上进行(幂运算)操作的数学手段就使得原式子的概率意义不那么明显了。2. 当$\\tau \\neq 1$的时候, 分母的值不为1。  \n","\n","验证:  \n","\n","\n","但是后面，我们可以通过数学举例验证,  ${P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{w'} P(w' | X) ^ {1 / \\tau} }$ 仍然是一个离散概率分布。这个验证最终要的一点就是要确保**各个token出现的概率和为1**, 那么作为验证，我们可以直接计算: \n","\n","$${P(w_{next}=w_1 | X) ^ {1 / \\tau} + P(w_{next}=w_2 | X) ^ {1 / \\tau}... + P(w_{next}=w_n | X) ^ {1 / \\tau} \\over \\sum_{w'} P(w' | X) ^ {1 / \\tau} } = {\\sum_{w'} P(w' | X) ^ {1 / \\tau}  \\over \\sum_{w'} P(w' | X) ^ {1 / \\tau} } = 1$$\n","\n","所以，某种程度上引入temperature parameter这个操作，对各个概率分布做了一个形式上为$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{w'} P(w' | X) ^ {1 / \\tau} }$的数学变换，(注意此式子的分母也不是1!，所以为什么我会说是在做normalization) 这个变换的作用，如上面所说，是把原概率分布进行一个转化: 这个转化的作用由$\\tau$的实际值控制，这句话说的很清楚:  $\\tau << 1$, more likely tokens will be sampled with even higher probability while less likely tokens will vanish,即当$\\tau$远小于1的时候，原概率会被重新分配为更倾向于选择概率最高的那个token, 举个例子，若原有且仅有3个token，它们被选中的概率依次为{0.3, 0.6, 0.1}的时候，若指定$\\tau$为0.1的话，那么经过这个分式变换之后，他们被选中的概率会变为{0.0009756097399785009, 0.9990243737379849, 1.652203661329577e-08} (这3个值可以自己算一下！)，很显然第2个token选中的概率从0.6飙升到了接近1, 也验证了$\\tau$在这里的作用: 为了本已经很显著的概率(即其概率相对其他事件很大)发生的概率更大，进行了一种数学意义上的放缩,这种放缩通过除以$\\sum_{w'} P(w' | X) ^ {1 / \\tau}$ 进行 **normalization**使得其仍然是一个概率形式。\n","\n","\n","所以本质上，上次提到的\"normalize\"我觉得"],"metadata":{"id":"R8gkppXPl7k0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_bUavwG2bjj","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649190962374,"user_tz":-120,"elapsed":3472,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"d1759dbc-5329-4dd4-afed-ed1483b61fb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({'been': 9084, 'not': 416, 'only': 168, 'also': 139, 'very': 70, 'lately': 65, 'occurred': 58})\n","Counter({'detections': 10000})\n"]}],"source":["\n","def get_next_token(lm, prefix, temperature=1.0):\n","    \"\"\"\n","    return next token after prefix;\n","    :param temperature: samples proportionally to lm probabilities ^ (1 / temperature)\n","        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n","    \"\"\"\n","    ############### for student ################\n","\n","    dict_token = lm.get_possible_next_tokens(prefix)\n","    sumup = sum([v for v in dict_token.values()])\n","    for k, v in dict_token.items():\n","        token_probs = v ** (1 / temperature)\n","        dict_token[k] = token_probs\n","    token_list = list(dict_token.keys())\n","    p = list(dict_token.values())\n","    p.pop()\n","    number = 1-sum(p)\n","    p.append(number)\n","    ############################################\n","    token = \"\".join(np.random.choice(token_list, 1,p=p))\n","    return token    \n","\n","test = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n","print(test)\n","test = Counter([get_next_token(lm, 'deep learning', temperature=0.9) for _ in range(10000)])\n","print(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rR7huhTz2bjm","pycharm":{"is_executing":true}},"outputs":[],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","from collections import Counter\n","test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n","assert 250 < test_freqs['not'] < 450\n","assert 8500 < test_freqs['been'] < 9500\n","assert 1 < test_freqs['lately'] < 200\n","test_freqs = Counter([get_next_token(lm, 'deep leanring', temperature=1.0) for _ in range(10000)])\n","assert 1500 < test_freqs['learning'] < 3000\n","test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n","assert test_freqs['learning'] == 10000\n","test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n","assert 8000 < test_freqs['learning'] < 9000\n","\n","print(\"Looks nice!\")"]},{"cell_type":"markdown","metadata":{"id":"4putrZEE2bjo"},"source":["Let's have fun with this model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpZkqe6B2bjp","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649189203896,"user_tz":-120,"elapsed":279,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"311f23a9-4329-4677-87d0-fb349cd6affb"},"outputs":[{"output_type":"stream","name":"stdout","text":["artificial immune system metaphors that are learned out of reach for alberti ' s speed prior is decomposable , two loaded dice are rolled . a crf that accounts for neighboring pixels are equal : deep translation and syntactic information ) in a manner that is present in the color intensity between nodes in alarm that are based on random forests . the experiments demonstrates the superior performance of the proposed modified hybrid evolutionary algorithm influence the success of deep networks , provide contexts with quantitative and qualitative improvement over pac ( passive ) latent discrete states , the same semantic\n"]}],"source":["prefix = 'artificial' # <- your ideas on the start of your AI generated scientific paper :)\n","\n","for i in range(100):\n","    prefix += ' ' + get_next_token(lm, prefix)\n","    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n","        break\n","        \n","print(prefix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"haAMgd8E2bjr","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649189206034,"user_tz":-120,"elapsed":314,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7fef4be-58e6-4927-c570-8e2d9ece474f"},"outputs":[{"output_type":"stream","name":"stdout","text":["bridging the gap between quantum indeterminism , freedom and free viewpoint video , previously - computed output . nevertheless , errors still persist . this actually acts as soft evidence in forensic applications , adaptation techniques address the research with his / her intervention in steering the system indicators . by accumulating the information diffusion process for such unsupervised training approach establish our recurrent auto - encoder suitable for classifying e - commerce requires a relatively inexpensive monocular camera mounted on moving frames . keyword spotting , an increasingly high level motivation is to benchmark state - of - readmission as a\n"]}],"source":["prefix = 'bridging the' # <- more of your ideas\n","\n","for i in range(100):\n","    prefix += ' ' + get_next_token(lm, prefix, temperature=0.4)\n","    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n","        break\n","        \n","print(prefix)"]},{"cell_type":"markdown","metadata":{"id":"-nTsCEeCrBJv"},"source":["### Question 1 \n","How does the temperature parameter affect the generated samples?\n","\n","**<font color=blue><<< Lower temperatures make the model increasingly confident in its top choices, while temperatures greater than 1 decrease confidence. 0 temperature is equivalent to argmax/max likelihood, while infinite temperature corresponds to a uniform sampling.  >>></font>**"]},{"cell_type":"markdown","metadata":{"id":"eSFf9Xxn2bju"},"source":["### **Evaluating language models: perplexity**\n","\n","Perplexity is a measure of how well your model approximates the true probability distribution behind the data. __Smaller perplexity = better model__.\n","\n","To compute the perplexity on one sentence, we can use:\n","$$\n","    {\\mathbb{P}}(w_1 \\dots w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_t P(w_t \\mid w_{t - n}, \\dots, w_{t - 1})\\right)^{-\\frac1N},\n","$$\n","\n","\n","On the corpus level, N would be equal to the __total length of all sentences__ in the corpora, and the product is taken over the probabilities of all tokens in all sentences. \n","\n","This number can quickly get too small for float32/float64 precision, so we recommend you to first compute the log-perplexity (take the log of the formula above, to transform it into a sum of log-probabilities) and then take the exponent to get the perplexity itself. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18C1wbQ_2bjv","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649192075528,"user_tz":-120,"elapsed":251,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a213323-d4ba-480b-ef9e-bac424c5b98f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":79}],"source":["def perplexity(lm, lines, min_logprob=np.log(10 ** -50.)):\n","    \"\"\"\n","    :param lines: a list of strings with space-separated tokens\n","    :param min_logprob: if log(P(w | ...)) is smaller than min_logprob, set it equal to min_logrob\n","    :returns: corpora-level perplexity - a single scalar number from the formula above\n","    \n","    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n","    \n","    PLEASE USE lm.get_next_token_prob and NOT lm.get_possible_next_tokens\n","    \"\"\"\n","\n","    \n","    N = 0  # number of tokens\n","    ppl = 0.0 # perplexity\n","    log_prob_sum = 0\n","    string = \" \"\n","    # https://stats.stackexchange.com/questions/129352/how-to-find-the-perplexity-of-a-corpus\n","    ############### for student ################\n","    for line in lines:\n","        string += line\n","    string_list = string.split(\" \") + [EOS]\n","    for i, w in enumerate(string_list):\n","        # print(i,w)\n","        prob = lm.get_next_token_prob(\" \".join(string_list[:i-1]),w)\n","        #print(i,w,prob)\n","        N += 1\n","        #print(max(np.log(prob),min_logprob), np.exp(-max(np.log(prob),min_logprob)))\n","        log_prob_sum += max(np.log(prob),min_logprob)\n","        # print(log_prob_sum)\n","        ppl = (-1/N)*log_prob_sum\n","\n","                \n","    ############################################\n","    \n","    return ppl\n","lm1 = NGramLanguageModel(dummy_lines, n=10)\n","lm1.get_next_token_prob('the jabberwock , with eyes','of')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qd_S3CgK2bjy","pycharm":{"is_executing":true},"executionInfo":{"status":"error","timestamp":1649184875273,"user_tz":-120,"elapsed":1270,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"0ce4b28f-0d72-48f5-aad0-9f182fee1467"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log\n"]},{"output_type":"stream","name":"stdout","text":["Perplexities: ppx1=9.971 ppx3=114.663 ppx10=115.045\n"]},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-276-60726a701fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mppx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mppx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mppx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppx10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"perplexity should be nonnegative and reasonably small\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppx_missing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mppx_missing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"missing words should have large but finite perplexity. \"\u001b[0m     \u001b[0;34m\" Make sure you use min_logprob right\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mppx1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mppx3\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mppx10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"higher N-gram models should overfit and have lower ppl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: missing words should have large but finite perplexity.  Make sure you use min_logprob right"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","lm1 = NGramLanguageModel(dummy_lines, n=1)\n","lm3 = NGramLanguageModel(dummy_lines, n=3)\n","lm10 = NGramLanguageModel(dummy_lines, n=10)\n","\n","ppx1 = perplexity(lm1, dummy_lines)\n","ppx3 = perplexity(lm3, dummy_lines)\n","ppx10 = perplexity(lm10, dummy_lines)\n","ppx_missing = perplexity(lm3, ['the jabberwock , with eyes of flame , '])\n","\n","print(\"Perplexities: ppx1=%.3f ppx3=%.3f ppx10=%.3f\" % (ppx1, ppx3, ppx10))\n","\n","assert all(0 < ppx < 500 for ppx in (ppx1, ppx3, ppx10)), \"perplexity should be nonnegative and reasonably small\"\n","assert np.isfinite(ppx_missing) and ppx_missing > 10 ** 6, \"missing words should have large but finite perplexity. \" \\\n","    \" Make sure you use min_logprob right\"\n","assert ppx1 > ppx3 > ppx10, \"higher N-gram models should overfit and have lower ppl\"\n","\n","assert np.allclose([ppx1, ppx3, ppx10], (318.2132342216302, 1.5199996213739575, 1.1838145037901249))\n","\n","print('Well done!')"]},{"cell_type":"markdown","metadata":{"id":"pPvh4rw_2bj0"},"source":["Now let's measure the actual perplexity: we'll split the data into train and test and score model on test data only."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qN0hUDIn2bj1","pycharm":{"is_executing":true}},"outputs":[],"source":["train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=SEED)\n","\n","for n in (1, 2, 3):\n","    lm = NGramLanguageModel(n=n, lines=train_lines)\n","    ppx = perplexity(lm, test_lines)\n","    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))\n"]},{"cell_type":"markdown","metadata":{"id":"vEPXFNpVrBJ3"},"source":["### Question 2\n","Do you expect increasing/decreasing perplexities for language models with longer n-grams (i.e., higher values of n)? Does this correspond with the test output you observe above? If not: can you explain this?\n","\n","**<font color=blue><<< No, when n increases, the condition to predict next word is more strict, and the most probable word is harder to be found, leading to predict 0, which increases the perplexity. >>></font>**"]},{"cell_type":"markdown","metadata":{"id":"wsAKFXD8yCO3","pycharm":{"name":"#%% md\n"}},"source":["###  LM Smoothing\n","\n","The problem with our simple language model is that whenever it encounters an n-gram it has never seen before, it assigns it the probabilitiy of 0. Every time this happens, the perplexity explodes.\n","To battle this issue, there's a technique called __smoothing__. \n","\n","The core idea is to modify counts in a way that prevents probabilities from getting too low. The simplest algorithm here is _additive smoothing_ (aka [Lapace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)):\n","\n","$$ P(w | \\textit{prefix}) = \\frac{\\textit{Count}(\\textit{prefix}, w) \\color{red}{+ \\delta}}{\\sum_{w' \\in \\textit{Vocab}}(\\textit{Count}(\\textit{prefix}, w') \\color{red}{+ \\delta})} $$\n","\n","If counts for a given prefix are low, additive smoothing will adjust the probabilities to a more uniform distribution, by assigning some of the original probability mass to unseen words. \n","\n","We update the `self.probs` attribute inside the constructor (`__init__`) to handle smoothing. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O83GCDSbMfSv","pycharm":{"is_executing":true}},"outputs":[],"source":["class LaplaceLanguageModel(NGramLanguageModel): \n","    def __init__(self, lines, n, delta=1.0):\n","        self.n = n\n","        counts = count_ngrams(lines, self.n) # \n","        self.vocab = set(token for token_counts in counts.values() for token in token_counts) #\n","        self.probs = defaultdict(Counter)\n","        \n","        for prefix in counts:\n","            token_counts = counts[prefix]\n","            total_count = sum(token_counts.values()) + delta * len(self.vocab) # denominator\n","            for token in token_counts:\n","                self.probs[prefix][token] = (token_counts[token] + delta) / total_count \n","\n","    def get_possible_next_tokens(self, prefix):\n","        token_probs = super().get_possible_next_tokens(prefix)\n","        missing_prob_total = 1.0 - sum(token_probs.values())\n","        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n","        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n","\n","    def get_next_token_prob(self, prefix, next_token):\n","        token_probs = super().get_possible_next_tokens(prefix)\n","        if next_token in token_probs:\n","            return token_probs[next_token]\n","        else:\n","            missing_prob_total = 1.0 - sum(token_probs.values())\n","            missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n","            return missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jk3hCsLiEJEU","pycharm":{"is_executing":true,"name":"#%%\n"},"scrolled":true},"outputs":[],"source":["# calculate perplexity for LaplaceLanguageModel\n","\n","from sklearn.model_selection import train_test_split\n","train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=SEED)\n","\n","for n in (1, 2, 3):\n","    lm = LaplaceLanguageModel(n=n, lines=train_lines)\n","    ppx = perplexity(lm, test_lines)\n","    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"]},{"cell_type":"markdown","metadata":{"id":"1lS9tYi3rBKA"},"source":["### Question 3\n","In a bigram language model (without smoothing), which of the following two phrases do you expect to have higher probablity? Why?\n"," - *and and*\n"," - *this paper* \n","\n","**<font color=blue><<< \"this paper\" has higher probability. It can be explained in 2 aspects: (1) \"and and\" barely appear in English except in spoken English. (2)model above can be used to validate the suspection: the probability of \"this paper\" is 0.46 while \"and and\" is 0.\n","  >>></font>**"]},{"cell_type":"markdown","metadata":{"id":"DMOD2JQw6l_g"},"source":["### Question 4\n","\n","If we add smoothing, how would the probability relation change for the above phrases? \n","\n","**<font color=blue><<< \"and and\" is not 0 when it is added smoothing, but the number is still quite small, smaller than \"this paper\" >>></font>**"]},{"cell_type":"markdown","metadata":{"id":"4AWJ09IbrBKB"},"source":["Train both language models (smoothing and non-smoothing version) on `dummy_lines` and report perplexity for the given phrases."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWYPIVS8rBKC","pycharm":{"is_executing":true,"name":"#%%\n"}},"outputs":[],"source":["# lm_names = [\"without smoothing\", \"with smoothing\"]\n","phrases = [[\"and and\"], [\"this paper\"]]\n","    \n","lmu = LaplaceLanguageModel(dummy_lines, n=2, delta = 0)\n","lms = LaplaceLanguageModel(dummy_lines, n=2, delta = 1)\n","\n","for lm_name,lmx in [(\"without smoothing\", lmu), (\"with smoothing\", lms)]:\n","    for phrase in phrases:\n","        ppl = perplexity(lmx, phrase)\n","        \n","        print(\"%s: phrase = '%s' --> pp = %.2E\" % (lm_name, phrase, ppl))\n","        "]},{"cell_type":"markdown","metadata":{"id":"WWVsI9znVJgE"},"source":["## **Deep Learning Based Language Models**\n","\n","We've checked out statistical approaches to language models so far. Now let's go find out what deep learning has to offer. We're gonna use the same dataset as before. \n","\n","\n","![alt text](https://vipulvaibhaw.files.wordpress.com/2019/04/saltbae_pytorch.jpg)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qDQAvQiNELH8","pycharm":{"name":"#%% md\n"}},"source":["We are going to implement the simplest recurrent neural network (RNN) known as the Elman RNN. Its hidden state aims to encapsulate the information for all previous input elements in order to help the network to take into account *the past*. Since there is no hidden state during the first step, we feed the network with an initial state of zero values (or randomly initilized values). Next, we feed it the first token ($\\textit{A}$) together with the hidden state of the previous step, to predict the next output ($\\textit{girl}$). We'll repeat this procudure until the end of sequence. \n","\n","We can summarize the above explanation into a simple equation as:\n","\n","$$h_t = F(x_{t}, h_{t-1}) = f(W_{x}x_t + W_{h}h_{t-1} + b),$$\n","\n","where $x_{t}$ is input, $h_{t}$ is hidden state, $b$ is bias term and $f$ is the `tanh` non-linearity.\n","\n","<a href=\"https://ibb.co/TcWR5CQ\"><img src=\"https://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Recurrent-neural-network.png\" border=\"0\"></a>\n","\n","**Before proceeding, please check if your Colab notebook is running on a GPU. To do this, go to \"Edit\", then \"Notebook settings\" and select \"GPU\" as a hardware accelerator.**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"CEcJFRkIrBKF","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703799831,"user_tz":-120,"elapsed":5562,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"8ddc55cd-d93d-49e3-92c3-6a2598177a05"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["### If you don't have pytorch yet: install it in the current kernel first .\n","### Uncomment next 2 lines to do that.\n","# import sys\n","# !conda install --yes --prefix {sys.prefix} pytorch\n","\n","# first import necessary packages\n","import torch\n","import torch.nn as nn\n","\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","# for reproducibility \n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","\n","torch.backends.cudnn.enabled = False \n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"n4_fr0ct2Mm3","pycharm":{"name":"#%% md\n"}},"source":["### **Tokenization**\n","\n","Before implementing the neural network itself, lets prepare the data. We need special tokens:\n","\n","* Begin Of Sequence  (__BOS__) - this token is at the start of each sequence. We use it so that we always have non-empty input to our neural network. $P(x_t) = P(x_1 | BOS)$\n","* End Of Sequence (__EOS__) - you guess it... this token is at the end of each sequence. The catch is that it should __not__ occur anywhere else except at the very end. If our model produces this token, the sequence is over.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"5YSv47V12LDg","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703808209,"user_tz":-120,"elapsed":4011,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["BOS, EOS = '<s>', '</s>'\n","text = [BOS + ' ' + line + ' ' + EOS for line in lines] # concatenate BOS and EOS to all sentences\n","text = [line.split() for line in text]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXpDD07qrBKN","pycharm":{"is_executing":true,"name":"#%%\n"}},"outputs":[],"source":["# let's print the first sentence \n","print(text[0])"]},{"cell_type":"markdown","metadata":{"id":"i5jp_3uQ_iHT","pycharm":{"name":"#%% md\n"}},"source":["Let us convert our raw text into sequences of ids. Our goal is to create a representation of the tokens which our model will be able to manipulate.\n","\n","First, we create two sorted dictionaries and map each token to an id. Second, we create the target data sequences based on the input. Note that the target is the same as the input, except that it is one token ahead of the input. This way, we can later teach our model to predict the next token in the sentence. "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"8KWb98fYCLJ0","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703820553,"user_tz":-120,"elapsed":399,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["from collections import Counter\n","\n","def get_data_lm(data):\n","    \n","    word_counts = Counter()\n","    for sent in data:\n","        word_counts.update(sent)\n","\n","    sorted_token = sorted(word_counts, key=word_counts.get, reverse=True)\n","    \n","    # create two dictionaries to convert token to id or vice-verca\n","    id_to_token = {k: w for k, w in enumerate(sorted_token)}\n","    token_to_id = {w: k for k, w in id_to_token.items()}\n","    \n","    n_token = len(id_to_token)\n","    \n","    tokenized_text = [[token_to_id[w] for w in sent] for sent in data]\n","    \n","    # output is one token ahead\n","    inp_text = [sent[:-1] for sent in tokenized_text]\n","    out_text = [sent[1: ] for sent in tokenized_text]\n","\n","    return id_to_token, token_to_id, n_token, inp_text, out_text"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"zzdcPMY1L3nb","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703826349,"user_tz":-120,"elapsed":268,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"670c350f-ec1e-4f7f-be6f-37f491c273eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["-- raw text: [['<s>', 'dual', 'recurrent', 'attention', 'units', 'for', 'visual', 'question', 'answering', ';', 'we', 'propose', 'an', 'architecture', 'for', 'vqa', 'which', 'utilizes', 'recurrent', 'layers', 'to', 'generate', 'visual', 'and', 'textual', 'attention', '.', 'the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question', '.', 'our', 'single', 'model', 'outperforms', 'the', 'first', 'place', 'winner', 'on', 'the', 'vqa', '1', '.', '0', 'dataset', ',', 'performs', 'within', 'margin', 'to', 'the', 'current', 'state', '-', 'of', '-', 'the', '-', 'art', 'ensemble', 'model', '.', 'we', 'also', 'experiment', 'with', 'replacing', 'attention', 'mechanisms', 'in', 'other', 'state', '-', 'of', '-', 'the', '-', 'art', 'models', 'with', 'our', 'implementation', 'and', 'show', 'increased', 'accuracy', '.', 'in', 'both', 'cases', ',', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset', '.', '</s>']]\n","----------------------------------------------------------------------------------------------------\n","-- input text: [[24, 25, 6, 3, 13, 14, 7, 15, 26, 27, 16, 28, 29, 30, 14, 8, 31, 32, 6, 33, 9, 34, 7, 4, 17, 3, 1, 0, 35, 36, 5, 0, 37, 6, 3, 13, 38, 39, 40, 41, 42, 5, 7, 4, 17, 43, 4, 44, 0, 10, 9, 45, 46, 47, 48, 49, 5, 0, 50, 4, 15, 1, 11, 51, 10, 52, 0, 53, 54, 55, 18, 0, 8, 56, 1, 57, 19, 20, 58, 59, 60, 9, 0, 61, 21, 2, 5, 2, 0, 2, 22, 62, 10, 1, 16, 63, 64, 23, 65, 3, 66, 12, 67, 21, 2, 5, 2, 0, 2, 22, 68, 23, 11, 69, 4, 70, 71, 72, 1, 12, 73, 74, 20, 11, 6, 3, 75, 76, 77, 12, 78, 79, 80, 81, 82, 83, 18, 0, 8, 19, 1]]\n","----------------------------------------------------------------------------------------------------\n","-- output text: [[25, 6, 3, 13, 14, 7, 15, 26, 27, 16, 28, 29, 30, 14, 8, 31, 32, 6, 33, 9, 34, 7, 4, 17, 3, 1, 0, 35, 36, 5, 0, 37, 6, 3, 13, 38, 39, 40, 41, 42, 5, 7, 4, 17, 43, 4, 44, 0, 10, 9, 45, 46, 47, 48, 49, 5, 0, 50, 4, 15, 1, 11, 51, 10, 52, 0, 53, 54, 55, 18, 0, 8, 56, 1, 57, 19, 20, 58, 59, 60, 9, 0, 61, 21, 2, 5, 2, 0, 2, 22, 62, 10, 1, 16, 63, 64, 23, 65, 3, 66, 12, 67, 21, 2, 5, 2, 0, 2, 22, 68, 23, 11, 69, 4, 70, 71, 72, 1, 12, 73, 74, 20, 11, 6, 3, 75, 76, 77, 12, 78, 79, 80, 81, 82, 83, 18, 0, 8, 19, 1, 84]]\n"]}],"source":["id_to_token, token_to_id, n_token, inp_text, out_text = get_data_lm(text[0:1])\n","\n","print(\"-- raw text:\", text[0:1])\n","print('-' * 100)\n","print(\"-- input text:\", inp_text)\n","print('-' * 100)\n","print(\"-- output text:\", out_text)"]},{"cell_type":"markdown","metadata":{"id":"8XxSBfxkGpj1","pycharm":{"name":"#%% md\n"}},"source":["For training, we won't put the entire sequence through the model at once. As explained in the theory lectures, we will limit the sequence length over which we apply back-propagation (which we'll call the *bptt length*, or the back-propagation-through-time length), and arrange the bptt-long segments into mini-batches for parallel training (also see the slides, for considerations on choosing the mini-batch size).\n","\n","Let us first convert the sequences into **mini-batches**"]},{"cell_type":"markdown","metadata":{"id":"bjZR3aS1Gen-"},"source":["Suppose our batch size is 4 (for benefiting from a gpu, you'll need to scale this up), bptt is 3 (in practice it will be much longer, though), and our data consists of a 1-dimensional tensor containing 36 token id's. Each batch will contain a 4x3 input tensor and a 4x3 target tensor, except for the last batch (we can discard the last one during training). As you already know, the target batch is one token ahead (in terms of the original sequence) of the input batch, since our task is language modeling (i.e. predicting the next word). The input/output tensor for the first batch will be something like the following:\n","\n","**Input batch**:\n","\n","![alt text](https://miro.medium.com/max/522/1*DVCsHtcfX8Hrb-1BJg92fw.png)\n","\n","**Target batch**:\n","\n","![alt text](https://miro.medium.com/max/504/1*gczU2zRHXnQ0SgXLanIK9g.png)"]},{"cell_type":"markdown","metadata":{"id":"Nxnxl7IIrBKX"},"source":["We'll convert the input (`inp_text`) and target (`out_text`) indices from the previous steps into mini-batches as follows:"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"a4flBYwz3M3t","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703832806,"user_tz":-120,"elapsed":276,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["from itertools import chain \n","from sklearn.utils import shuffle\n","\n","def get_batches(inp_text, out_text, batch_size, seq_size):\n","    \n","    # shuffle the sentences\n","    itext, otext = shuffle(inp_text, out_text)\n","    \n","    # flatten the data\n","    itext = list(chain(*itext))\n","    otext = list(chain(*otext))\n","    \n","    # work out how cleanly we can divide the dataset into batch_size parts.\n","    num_batches = int(len(itext) / (seq_size * batch_size))\n","    \n","    # trim off any extra elements that wouldn't cleanly fit\n","    itext = itext[:num_batches * batch_size * seq_size] \n","    otext = otext[:num_batches * batch_size * seq_size]\n","\n","    itext = np.reshape(itext, (batch_size, -1)) # batch_size * tokens\n","    otext = np.reshape(otext, (batch_size, -1)) # batch_size * tokens\n","    \n","    for i in range(0, num_batches * seq_size, seq_size):\n","        yield itext[:, i:i + seq_size], otext[:, i:i + seq_size]"]},{"cell_type":"markdown","metadata":{"id":"TNfRxe7CrBKa"},"source":["### Question 5\n","\n","If you study the `get_batches` code, you’ll see that only complete batches are generated (i.e., containing `batch_size` times `seq_size` instances). If the dataset size is no multiple of this number, this means the incomplete final batch is ignored. Do you think that is a problem in terms of the capabilities of the final trained model? Please motivate.\n","\n","**<font color=blue><<< I think there are two things that can be considered:\n","(1) the distribution of incomplete batches can be checked and reviewed. (2) the size of dataset. For (1), if the distribution abides by uniform distribution, we can ignore the incomplete batch; for (2) if the dataset is big enough to cover all cases of the batches, incomplete batches can be cleaned.\n"," >>></font>**"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"TAX_L9btrBKb","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703840269,"user_tz":-120,"elapsed":12,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"8a1cc6b0-b0af-4054-8465-758d164066ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["batch  0\n","input: (4, 10)\n","x: [[24 25  6  3 13 14  7 15 26 27]\n"," [ 5  0 37  6  3 13 38 39 40 41]\n"," [15  1 11 51 10 52  0 53 54 55]\n"," [22 62 10  1 16 63 64 23 65  3]]\n","-----------------------------------\n","target: (4, 10)\n","y: [[25  6  3 13 14  7 15 26 27 16]\n"," [ 0 37  6  3 13 38 39 40 41 42]\n"," [ 1 11 51 10 52  0 53 54 55 18]\n"," [62 10  1 16 63 64 23 65  3 66]]\n","-----------------------------------\n","-----------------------------------\n","batch  1\n","input: (4, 10)\n","x: [[16 28 29 30 14  8 31 32  6 33]\n"," [42  5  7  4 17 43  4 44  0 10]\n"," [18  0  8 56  1 57 19 20 58 59]\n"," [66 12 67 21  2  5  2  0  2 22]]\n","-----------------------------------\n","target: (4, 10)\n","y: [[28 29 30 14  8 31 32  6 33  9]\n"," [ 5  7  4 17 43  4 44  0 10  9]\n"," [ 0  8 56  1 57 19 20 58 59 60]\n"," [12 67 21  2  5  2  0  2 22 68]]\n","-----------------------------------\n","-----------------------------------\n","batch  2\n","input: (4, 10)\n","x: [[ 9 34  7  4 17  3  1  0 35 36]\n"," [ 9 45 46 47 48 49  5  0 50  4]\n"," [60  9  0 61 21  2  5  2  0  2]\n"," [68 23 11 69  4 70 71 72  1 12]]\n","-----------------------------------\n","target: (4, 10)\n","y: [[34  7  4 17  3  1  0 35 36  5]\n"," [45 46 47 48 49  5  0 50  4 15]\n"," [ 9  0 61 21  2  5  2  0  2 22]\n"," [23 11 69  4 70 71 72  1 12 73]]\n","-----------------------------------\n","-----------------------------------\n"]}],"source":["bs = 4\n","bptt = 10\n","batches = get_batches(inp_text, out_text, bs, bptt)\n","\n","i = 0\n","for x,y in batches:\n","    print('batch ', i)\n","    print('input:', x.shape)\n","    print(\"x:\",x)\n","    print('-' * 35)\n","    print('target:', y.shape)\n","    print(\"y:\", y)\n","    print('-' * 35)\n","    print('-' * 35)\n","    i += 1"]},{"cell_type":"markdown","metadata":{"id":"8a3wrsxdHpsO","pycharm":{"name":"#%% md\n"}},"source":["### **Let's build the model**\n","\n","By extending the `nn.Module` you can easily develop your own recurrent cell in pytorch. In this part we will implement an **Elman** Recurrent Network. This module receives a sequence of feature vectors and returns two tensors. Please study the nodes as defined in `__init__` and initialized using `init_weights`, and correctly fill in the `forward` method in line with the formula for the Elman RNN. \n","\n","Note that the `forward` function returns both the current `state` and a `hidden_seq`. The `state` variable represents the final state of the RNN after digesting the entire sequence `x`. The `hidden_seq` is the output of the RNN, and is made up of all past hidden states the RNN moved through to arrive at `state`. \n","\n","Please note that potentially large tensors (such as input sequences and states) should be put on the correct device (stored in the parameter `device`) in order to benefit from the use of a GPU. You can refer to the evaluation cell below for an example on using `.to(device)`. In the forward pass, the data `x` that is passed along will already be on a device, but you will need to put the hidden state on the same device yourself after initialization (see comments in the code). "]},{"cell_type":"code","execution_count":14,"metadata":{"id":"1gVBw_VvFo27","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703858987,"user_tz":-120,"elapsed":9824,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"7528a3bb-de4b-4973-87a6-a09c2532e0ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.9056,  0.0905],\n","         [-0.8311,  0.2465]],\n","\n","        [[-0.6397,  0.2327],\n","         [-0.6608,  0.2948]],\n","\n","        [[-0.8347, -0.6351],\n","         [-0.9661, -0.5308]],\n","\n","        [[-0.8675, -0.2413],\n","         [-0.9104, -0.5339]],\n","\n","        [[-0.8729, -0.2497],\n","         [-0.7836,  0.0473]],\n","\n","        [[-0.4898,  0.1880],\n","         [-0.6810,  0.3480]],\n","\n","        [[-0.2498,  0.1702],\n","         [-0.4862, -0.2328]],\n","\n","        [[-0.5826, -0.4683],\n","         [-0.9264, -0.7755]],\n","\n","        [[-0.8741, -0.2414],\n","         [-0.8405,  0.1610]],\n","\n","        [[-0.8105,  0.3501],\n","         [-0.7365, -0.4609]]], device='cuda:0', grad_fn=<TransposeBackward0>)\n","tensor([[-0.8311,  0.2465],\n","        [-0.6608,  0.2948],\n","        [-0.9661, -0.5308],\n","        [-0.9104, -0.5339],\n","        [-0.7836,  0.0473],\n","        [-0.6810,  0.3480],\n","        [-0.4862, -0.2328],\n","        [-0.9264, -0.7755],\n","        [-0.8405,  0.1610],\n","        [-0.7365, -0.4609]], device='cuda:0', grad_fn=<TanhBackward0>)\n"]}],"source":["class RNN(nn.Module):\n","    def __init__(self, input_sz, hidden_sz):\n","        super(RNN, self).__init__()\n","        # necessary parameters in Elman RNN\n","        self.input_sz = input_sz\n","        self.hidden_sz = hidden_sz\n","        \n","        self.fc_x = nn.Linear(self.input_sz, self.hidden_sz, bias=False) ####hidden_size是我们自己定义的，是每层神经元的neuron的个数，而不是hidden state;hidden state表示 f(wx+wh+b)\n","        \n","        self.fc_h = nn.Linear(self.hidden_sz, self.hidden_sz) #default: bias = True\n","        self.tanh = nn.Tanh()\n","        \n","        self.init_weights()  ##init只会在\n","        ####self相当于一个存储器（字典），如果self.ssss没有等于，则相当于是运行；如果self.ssss有等于，则相当于是将self.之后的等式存起来；\n","    def init_weights(self):\n","        \n","        nn.init.xavier_uniform_(self.fc_x.weight)\n","        nn.init.xavier_uniform_(self.fc_h.weight)\n","        self.fc_h.bias.data.fill_(0.0)\n","    \n","    def forward(self, x, state=None):\n","        \"\"\"\n","        :param x: batch of sequences of input symbols (represented as vectors)\n","                  dimensions of x will be batch_size * sequence_length * input_sz\n","        :param state: state vector, of size self.hidden_sz\n","        :return: hidden_seq, state; where state is final output state,\n","                 hidden_seq is list of hidden states h_t (see fig. above)\n","        \"\"\"\n","        \n","        # things to do:\n","        # 1) if state is None, initialize it with zeros (use `torch.zeros`)\n","        #    please do not forget to put the state on the device after initialization\n","        #    (you can access the device through x.device)\n","        # 2) iterate over time, each time applying the RNN formula, and\n","        #    concatenate the state tensors to hidden_seq (with `torch.cat`)\n","        # 3) reshape hidden_seq from (seq, batch, feature) to (batch, seq, feature), with `Tensor.transpose`\n","        \n","        hidden_seq = []\n","        ############### for student ################\n","        batch_size = x.shape[0]\n","        seq_len = x.shape[1]\n","        # print(x.shape)\n","        # print(x[:2:].shape)\n","        \n","        # mini_batch_size = batch_size * bptt\n","        if state is None:\n","            state = torch.zeros(batch_size, self.hidden_sz).to(device)\n","            # h_state = torch.zeros(batch_size, seq_len, self.hidden_sz).to(device)\n","            # print(state.shape)\n","        for t in range(seq_len):\n","            mini_batch = x[:,t,:]\n","            # print(\"mini:\", mini_batch.shape)\n","            wx = self.fc_x(mini_batch) ##将上一层的计算结果结合输入x，得到新的\n","            wh = self.fc_h(state).to(device)\n","            tmp = wx + wh\n","            hidden_state = nn.Tanh()(tmp)###h0传递给下一个隐藏层\n","            state = hidden_state\n","            # print(\"state:\", state)\n","            # print(\"unsqueeze:\",torch.unsqueeze(state,1))\n","            hidden_seq.append(state)\n","        hidden_seq = torch.cat([s_tensor.unsqueeze(0) for s_tensor in hidden_seq],0)\n","        # print(\"hidden_seq.shape:\",hidden_seq.shape)       \n","\n","            #hidden_seq = torch.concat((torch.tensor(hidden_seq, device ='cpu').to(device), state),0)\n","        # print(\"hidden_seq\", hidden_seq)\n","        hidden_seq = torch.transpose(hidden_seq, 0, 1)\n","\n","        \n","        ############################################\n","        return hidden_seq, state\n","\n","arr = torch.rand([10, 2, 2]).to(device)\n","# print(arr)\n","# print(arr)\n","my_rnn = RNN(2,2).to(device)  ###已经得到了w，就不用再运行了权重初始化，因为w初始化只会在init函数中运行一次\n","\n","my_rnn.forward(arr, state=None)\n","out, state = my_rnn(arr) \n","# print(my_rnn(arr))\n","print(out)\n","print(state)\n","# print(state.shape)\n","# print(state.shape)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"HiVk59-DSaTi","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703869863,"user_tz":-120,"elapsed":322,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"d42678a7-96c1-4e31-bc21-9312d5cb7d7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["RNNCell completed!\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","# Let's test the RNN module\n","arr = torch.rand([1, 2, 2]).to(device) # tensor dimension: batch size x bptt x features\n","my_rnn = RNN(2, 2).to(device)\n","out, state = my_rnn(arr) ####运行的是forward（）\n","\n","assert out.shape == torch.Size([1, 2, 2]), out.shape\n","assert state.shape == torch.Size([1, 2]), state.shape\n","\n","print(\"RNNCell completed!\")"]},{"cell_type":"markdown","metadata":{"id":"0Ldp30LUYPFT","pycharm":{"name":"#%% md\n"}},"source":["The recurrent module is only one part of the neural language model. We still need an embedding layer, to convert our tokens into a feature vector which can be used as an input of the recurrend module. We also need a decoding layer, which predicts subsequent tokens by converting the output sequence it receives from the recurrend module into a probability distribution. To this end, we defined a wrapper and put everything in it. We provided the necessary modules you'll need, please complete the `forward` function. "]},{"cell_type":"code","execution_count":16,"metadata":{"id":"tFiwFmga4hEA","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703875500,"user_tz":-120,"elapsed":645,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f21c9615-9c1e-4293-882f-cdc629f7296b"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 32])\n","RNNLanguageModel(\n","  (encoder): Embedding(85, 256)\n","  (rnn): RNN(\n","    (fc_x): Linear(in_features=256, out_features=256, bias=False)\n","    (fc_h): Linear(in_features=256, out_features=256, bias=True)\n","    (tanh): Tanh()\n","  )\n","  (decoder): Linear(in_features=256, out_features=85, bias=True)\n",")\n","x: torch.Size([64, 32])\n","emccoder: torch.Size([64, 32])\n","out: torch.Size([64, 32, 85])\n","tensor([[-0.8596, -0.5892,  0.9645,  ...,  0.9024,  0.9933, -0.9423],\n","        [-0.9505, -0.2804, -0.6816,  ..., -0.1923,  0.5199,  0.1026],\n","        [-0.3708, -0.8257,  0.3034,  ...,  0.8385,  0.5385, -0.5759],\n","        ...,\n","        [ 0.5262, -0.5304, -0.9990,  ..., -0.3147,  0.8549,  0.5646],\n","        [-0.9308,  0.4372, -0.7930,  ...,  0.7304,  0.2519, -0.6663],\n","        [-0.8494, -0.9355, -0.7951,  ...,  0.9109,  0.9828,  0.0445]],\n","       device='cuda:0', grad_fn=<TanhBackward0>)\n"]}],"source":["class RNNLanguageModel(nn.Module):\n","    def __init__(self, n_tokens, hidden_size):\n","        super(RNNLanguageModel, self).__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.encoder = nn.Embedding(n_tokens, hidden_size)  \n","        self.rnn = RNN(hidden_size, hidden_size)\n","        self.decoder = nn.Linear(hidden_size, n_tokens)\n","    \n","    def forward(self, x, prev_state):\n","        \"\"\"\n","        :return: logits, state; where logits = output of the decoder,\n","                 and state = the final rnn state.\n","        \"\"\"\n","        # call the Embedding, RNN and linear decoder layer in the forward pass\n","        ############### for student ################\n","        print(\"x:\", x.shape)\n","        embedding = self.encoder(x).to(device)\n","        print(\"emccoder:\", x.shape)\n","        out, state = self.rnn(embedding,prev_state)\n","        \n","        logits = self.decoder(out).to(device)\n","        ############################################ \n","        return logits,state       \n","\n","    def zero_state(self, batch_size):\n","        return torch.zeros(batch_size, self.hidden_size)\n","\n","\n","arr = torch.randint(n_token, [64, 32], dtype=torch.long).to(device)\n","print(arr.shape)\n","rnn_language_model = RNNLanguageModel(n_token, 256).to(device)\n","print(rnn_language_model)\n","state = rnn_language_model.zero_state(64).to(device)\n","out, state = rnn_language_model(arr, state)\n","print(\"out:\", out.shape)\n","print(state)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"uJ3NOjK7kftX","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703897729,"user_tz":-120,"elapsed":294,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"19a15a01-0030-4e8e-b976-94d45aa6aec3"},"outputs":[{"output_type":"stream","name":"stdout","text":["x: torch.Size([64, 32])\n","emccoder: torch.Size([64, 32])\n","Sounds good! The model is complete!\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","# Let's test the whole model\n","arr = torch.randint(n_token, [64, 32], dtype=torch.long).to(device)\n","\n","rnn_language_model = RNNLanguageModel(n_token, 256).to(device)\n","state = rnn_language_model.zero_state(64).to(device)\n","out, state = rnn_language_model(arr, state)\n","\n","assert type(out) != type(None), 'Do you return output?'\n","assert type(state) != type(None), 'Do you return state?'\n","assert out.shape == torch.Size([64, 32, n_token]), out.shape\n","assert state.shape == torch.Size([64, 256]), state.shape \n","print(\"Sounds good! The model is complete!\")"]},{"cell_type":"markdown","metadata":{"id":"Ekvi0-dsHie1","pycharm":{"name":"#%% md\n"}},"source":["### **Sampling**\n","\n","You will need a function to generate text. For your convenience, we have implemented it for you. The idea is to feed one token at a time to the model and concatenate the model's output token to previously predicted tokens. "]},{"cell_type":"code","execution_count":18,"metadata":{"id":"HIzIA8JUrBKq","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649703905015,"user_tz":-120,"elapsed":616,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["def sample(preds, n_token, temperature):\n","    if temperature == 0:\n","        choice = np.argmax(preds[0].tolist())\n","    else:\n","        preds = preds.squeeze() / temperature\n","        exp_preds = np.exp(preds.tolist())\n","        preds = exp_preds / np.sum(exp_preds)\n","        choice = np.random.choice([*range(n_token)], p=preds)\n","    return choice"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"D8MVYJ_LVPPl","pycharm":{"is_executing":true,"name":"#%%\n"},"executionInfo":{"status":"ok","timestamp":1649703925809,"user_tz":-120,"elapsed":337,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["def generate_text(device, net, n_token, token_to_id, id_to_token, temperature=1.0):\n","    # we are in evaluation mode\n","    net.eval()\n","\n","    # initialize state\n","    state_h = net.zero_state(1).to(device)\n","\n","    # manually feed some tokens\n","    initial_words = ['recurrent', 'neural']\n","    for w in initial_words:\n","        ix = torch.tensor([[token_to_id[w]]], dtype=torch.long).to(device)\n","        preds, state_h = net(ix, state_h)\n","    \n","    choice = sample(preds, n_token, temperature)\n","    initial_words.append(id_to_token[choice])\n","\n","    # generate next tokens (50 tokens at most!)\n","    for _ in range(50):\n","        ix = torch.tensor([[choice]], dtype=torch.long).to(device)\n","        preds, state_h = net(ix, state_h)\n","        choice = sample(preds, n_token, temperature)\n","        \n","#         # you can stop generation \n","#         if id_to_token[choice] == EOS:\n","#             break;\n","        \n","        initial_words.append(id_to_token[choice])\n","\n","\n","    return ' '.join(initial_words)"]},{"cell_type":"markdown","metadata":{"id":"oh9MrQinIxWp","pycharm":{"name":"#%% md\n"}},"source":["### **Training loop**\n","\n","A typical set of steps for training in Pytorch is:\n","\n","* set model in 'train' mode *(note: it will only inform the inner mechanism that we are about to train, but not actually execute the training; we still need to do that ourselves)*\n","* Reset all gradients\n","* Compute output, loss value, accuracy, etc\n","* Perform back-propagation to compute the gradients, based on the calculated loss\n","* Update the network’s parameters using an optimization scheme of your choice (here, we use Adam). "]},{"cell_type":"code","execution_count":20,"metadata":{"id":"gUxKy9PzrBKx","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703933748,"user_tz":-120,"elapsed":367,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"b6feaec9-2385-4c3a-ed2b-d25868c94acb"},"outputs":[{"output_type":"stream","name":"stdout","text":["2688\n"]}],"source":["seq_size = 32\n","batch_size = 16\n","hidden_size = 256\n","temperature = 1.0\n","\n","dummy_text = text[0:100]\n","id_to_token, token_to_id, n_token, inp_text, out_text = get_data_lm(dummy_text)\n","print(n_token)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"tvxqiXVZtYE_","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703983716,"user_tz":-120,"elapsed":47211,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"647f8223-9fe4-4525-de4e-0b3927135758"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","epoch: 43/100 iteration: 1549 loss: 0.3234245777130127\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 44/100 iteration: 1599 loss: 0.34232139587402344\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 45/100 iteration: 1649 loss: 0.3648602068424225\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 47/100 iteration: 1699 loss: 0.26816216111183167\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 48/100 iteration: 1749 loss: 0.3415567874908447\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural networks ( rnn ). this architecture is extended to the dual am - rnn which operates on two ams at once . our models achieve very competitive results reported to - date ( with 59 % relative improvement in generation ) on the benchmark weathergov of , open - domain conversational\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 49/100 iteration: 1799 loss: 0.33215054869651794\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 51/100 iteration: 1849 loss: 0.32769426703453064\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 52/100 iteration: 1899 loss: 0.32044529914855957\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 54/100 iteration: 1949 loss: 0.3148539066314697\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 55/100 iteration: 1999 loss: 0.28171950578689575\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural network ( rnn ) model for acoustic modelling in sequence modeling and target - target learning . for predicting the next token , these models query information from a memory of the recent history which can facilitate learning researchers to new copying and image . we show that lstm , layers\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 56/100 iteration: 2049 loss: 0.2868908643722534\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 58/100 iteration: 2099 loss: 0.2595195472240448\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 59/100 iteration: 2149 loss: 0.29070889949798584\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 61/100 iteration: 2199 loss: 0.2638934552669525\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 62/100 iteration: 2249 loss: 0.22908760607242584\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural networks ( propose ) vqa which automatically control how much value functions . </s> , competitive : ( rnn ) which is then perform in evaluate for the domain of language modelling ; neural networks , a novel processor dialog to - date of hidden the model on the robocup tasks\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 63/100 iteration: 2299 loss: 0.2743746340274811\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 65/100 iteration: 2349 loss: 0.2537030577659607\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 66/100 iteration: 2399 loss: 0.27410173416137695\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 68/100 iteration: 2449 loss: 0.24771267175674438\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 69/100 iteration: 2499 loss: 0.27873244881629944\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural networks ( rnn ). this architecture is extended to lack the rnn . this is publicly first , a general method with respect to the non - de - identified notes , and the frequent mistakes of human annotators . a reliable automated de - identification system would consequently be of\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 70/100 iteration: 2549 loss: 0.2583600878715515\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 72/100 iteration: 2599 loss: 0.2420983612537384\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 73/100 iteration: 2649 loss: 0.21303988993167877\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 74/100 iteration: 2699 loss: 0.237190380692482\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 76/100 iteration: 2749 loss: 0.22495661675930023\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural networks . in this work we compare a model architecture is the by many approaches have been used separately to produce significant performance gains for speaker and language recognition ; learned feature representations and sub - phoneme posteriors from deep neural networks ( youtube2text ) saved on multiple layers of long\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 77/100 iteration: 2799 loss: 0.23476958274841309\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 79/100 iteration: 2849 loss: 0.20328760147094727\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 80/100 iteration: 2899 loss: 0.3197534680366516\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 81/100 iteration: 2949 loss: 0.21227829158306122\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 83/100 iteration: 2999 loss: 0.22548232972621918\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural networks ( rnns ) for image description has motivated the exploration of their application for video description . oonp supports both other for natural language with recurrent neural networks . our evaluation suggest by 2 , 100 hours of dialogue system . our results demonstrate that this understand is extended to\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 84/100 iteration: 3049 loss: 0.1987721025943756\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 86/100 iteration: 3099 loss: 0.22956809401512146\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 87/100 iteration: 3149 loss: 0.23088444769382477\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 88/100 iteration: 3199 loss: 0.2367701530456543\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 90/100 iteration: 3249 loss: 0.1895187348127365\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural networks ( rnns ) for image description has motivated the exploration of their application for video description . however , while images are static , working with videos requires modeling their dynamic temporal structure and then properly integrating that information into a natural language description . in this context , we\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 91/100 iteration: 3299 loss: 0.18016621470451355\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 93/100 iteration: 3349 loss: 0.1899518072605133\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 94/100 iteration: 3399 loss: 0.227281853556633\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 95/100 iteration: 3449 loss: 0.24835985898971558\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 97/100 iteration: 3499 loss: 0.224922314286232\n","--------------------------------------------------\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","x: torch.Size([1, 1])\n","emccoder: torch.Size([1, 1])\n","recurrent neural networks with external neural network and template - based models . by applying reinforcement learning to crowdsourced data and real - world from recurrent neural networks ( qrnns ), an approach to neural sequence problems . such intrinsic behaviors could eventually help the agent solve tasks posed by the environment .\n","--------------------------------------------------\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 98/100 iteration: 3549 loss: 0.225276380777359\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n","epoch: 99/100 iteration: 3599 loss: 0.24277755618095398\n","x: torch.Size([16, 32])\n","emccoder: torch.Size([16, 32])\n"]}],"source":["net = RNNLanguageModel(n_token, hidden_size)\n","net = net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters())\n","\n","iteration = 0\n","total_epochs = 100\n","loss_history = []\n","\n","\n","for e in range(total_epochs):\n","    \n","    batches = get_batches(inp_text, out_text, batch_size, seq_size)\n","    \n","    state_h = net.zero_state(batch_size)\n","    state_h = state_h.to(device)\n","    \n","    for x, y in batches:\n","\n","        iteration += 1\n","\n","        x = torch.tensor(x).to(device)\n","        y = torch.tensor(y).to(device)\n","        # print(\"y\",y.shape)\n","\n","        # Things to do:\n","        # - put model in `train` mode\n","        # - set gradients to zero\n","        # - forward path\n","        # - loss calculation, using the criterion defined above\n","        # - compute gradient\n","        # - detach state representation by `detach()` (If we did not detach the history of hidden states \n","        #   the back-propagated gradients would flow from the loss towards the beginning)\n","        # - clip gradients (using grad_norm(=1))\n","        # - update parameters, using the optimizer defined above\n","        \n","        ############### for student ################\n","        optimizer.zero_grad() # clear gradients for this training step\n","        logits, state = net(x, state_h)\n","        # print(\"logits\",logits.shape)\n","        # print(type(output))               # rnn output\n","        loss = criterion(torch.transpose(logits,1,2), y)   # cross entropy loss\n","        loss.backward()                 # backpropagation, compute gradients\n","        optimizer.step()                # apply gradients\n","\n","        ############################################\n","\n","        if iteration % 50 == 49:\n","            print('epoch: {}/{} iteration: {} loss: {}'.format(e, total_epochs, iteration, loss.item()))\n","            \n","        if iteration % 250 == 249:\n","            print('-' * 50)\n","            print(generate_text(device, net, n_token, token_to_id, id_to_token, temperature))\n","            print('-' * 50)\n","    \n","    loss_history.append(loss.item())"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"j1k8Dim1rBK2","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649703992086,"user_tz":-120,"elapsed":529,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"5f711948-6890-45d9-bfe3-e152eac3f419"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fantastico!\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","assert sum(loss_history) / len(loss_history) < 2.0\n","assert loss_history[-1] < 1.0\n","\n","print('Fantastico!')"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ISzQG0TJrBK3","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1649703998388,"user_tz":-120,"elapsed":374,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"45788fe9-d730-414a-ce6d-56cb66a9118e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["epoch_count = range(1, len(loss_history) + 1) \n","\n","# Visualize loss history\n","plt.plot(epoch_count, loss_history, 'r--')\n","plt.legend(['Train Loss'])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TAQdYuMANRdv","pycharm":{"name":"#%% md\n"}},"source":["### **More powerful cell!**\n","\n","In the previous part, we implemented a simple Elman recurrent network. We can easily extend it to an **LSTM** by modifying our code slightly. Since we already learned how to implement the recurrent cell itself, in this part, we will simply use the existing pytorch `nn.LSTM` implementation. One major difference between these two networks is their **hidden state**. Unlike an Elman RNN which has only a single state, the hidden state of an LSTM is made up of two parts.\n","You can take a look at the online documentation of [`nn.LSTM`](https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) as well as [`nn.LSTMCell`](https://pytorch.org/docs/stable/nn.html?highlight=lstmcell#torch.nn.LSTMCell)\n","\n","<img src=\"https://www.knime.com/sites/default/files/fig_2_2.png\" alt=\"img\" width=\"512px\"/>\n","\n","Please fill in the forward function of the LSTM network."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"jxfZc9tpsC_1","pycharm":{"is_executing":true},"executionInfo":{"status":"ok","timestamp":1649704009545,"user_tz":-120,"elapsed":380,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["class LSTMLanguageModel(nn.Module):\n","    def __init__(self, n_tokens, hidden_sz):\n","        super(LSTMLanguageModel, self).__init__()\n","        self.hidden_size = hidden_sz\n","        \n","        self.embedding = nn.Embedding(n_tokens, hidden_sz)\n","        self.rnn = nn.LSTM(hidden_sz, hidden_sz, batch_first=True)\n","        self.decoder = nn.Linear(hidden_sz, n_tokens)\n","        \n","    def forward(self, x, prev_state):\n","        \"\"\"\n","        :return: logits, state; where logits is output of the decoder,\n","                 and state is the final rnn state.\n","        \"\"\"\n","        ############### for student ################\n","        embedding = self.embedding(x)\n","        out,state = self.rnn(embedding,prev_state)\n","        logits = self.decoder(out)\n","        return logits, state\n","        ############################################\n","    \n","    def zero_state(self, batch_size, dev):\n","        \"\"\"\n","        look up the dimensions of the nn.LSTM state (which is a tuple!)\n","        return a zero-initialized state\n","        put on the correct device (dev)\n","        \"\"\"\n","        return (torch.zeros(1, batch_size, self.hidden_size).to(dev),\n","                torch.zeros(1, batch_size, self.hidden_size).to(dev))\n","    "]},{"cell_type":"code","execution_count":25,"metadata":{"id":"WLGhjgJ9OiC_","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649704018232,"user_tz":-120,"elapsed":481,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"04a7aa51-e0ff-493f-bf66-47d235089d3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["LSTM is complete! Perfect!\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","# Let's test the LSTM model\n","arr = torch.randint(n_token, [64, 32], dtype=torch.long).to(device)\n","model = LSTMLanguageModel(n_token, 256).to(device)\n","state = model.zero_state(64, device)\n","out, state = model(arr, state)\n","\n","assert type(out) != type(None), 'Did you return output?'\n","assert type(state) != type(None), 'How about state?'\n","assert out.shape == torch.Size([64, 32, n_token]), out.shape\n","assert isinstance(state, tuple) \n","print(\"LSTM is complete! Perfect!\")"]},{"cell_type":"markdown","metadata":{"id":"54nLD9KQXe5d","pycharm":{"name":"#%% md\n"}},"source":["### **Evaluation method**\n","\n","So far, we have only evaluated the performance of our neural networks throughout the training loop, only calculating the loss for a single mini-batch at a time. Now, we will create an evaluation method to evaluate the performance of our network across multiple batches. \n","\n","Complete the __evaluate()__ method below so that it returns the overall (mean) cross-entropy loss. "]},{"cell_type":"code","execution_count":26,"metadata":{"id":"DFTyZlk8rBK_","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649704035779,"user_tz":-120,"elapsed":299,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"51367a16-8339-47b5-bbb9-8a71487fa63a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n"]}],"source":["def evaluate(device, net, n_token, batch_size, seq_size, x_test, y_test):\n","    \n","    net.eval()\n","    \n","    total_loss = 0.\n","    \n","    # intialize state\n","    state_h, state_c = net.zero_state(batch_size, device)\n","    state_h = state_h.to(device)\n","    state_c = state_c.to(device)\n","    print(state_h.shape)\n","    print(state_c.shape)\n","    \n","    # batchify data\n","    batches = get_batches(x_test, y_test, batch_size, seq_size)\n","    \n","    # 1) loop through the batches\n","    ##   convert data to tensor and put it on the device\n","    ##   calculate forward path\n","    ##   use 'criterion' (as defined earlier in the training loop) to calculate the loss for each mini-batch (reshape might be needed)\n","    ##   add mini-batch loss to total_loss\n","    ##   detach() states\n","    # 2) return average loss\n","    ############### for student ################\n","    iteration = 0\n","    for x, y in batches:\n","        iteration += 1\n","        x = torch.tensor(x).to(device)\n","        y = torch.tensor(y).to(device)\n","        out,(hn,cn) = net(x,(state_h,state_c))\n","        # print(out.shape)\n","        loss = criterion(torch.transpose(out,1,2), y)\n","        # print(loss)\n","        total_loss += loss\n","    average_loss = (total_loss/iteration).cpu().data\n","    # print(average_loss)\n","    return average_loss\n","\n","    \n","id_to_token, token_to_id, n_token, inp_text, out_text = get_data_lm(dummy_text)\n","net = LSTMLanguageModel(n_token, 256).to(device)    \n","dummy_loss = evaluate(device, net, n_token, 10, 64, inp_text, out_text)\n","        \n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    ############################################"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"aVtvPCsybsS1","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649704043744,"user_tz":-120,"elapsed":274,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"d74c0a76-1856-40d2-82ac-451dc2702c3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","It looks alright.\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","id_to_token, token_to_id, n_token, inp_text, out_text = get_data_lm(dummy_text)\n","net = LSTMLanguageModel(n_token, 256).to(device)\n","dummy_loss = evaluate(device, net, n_token, 10, 64, inp_text, out_text)\n","\n","assert np.exp(dummy_loss) < 1e4, 'your dummy loss is too large!'\n","\n","print(\"It looks alright.\")"]},{"cell_type":"markdown","metadata":{"id":"QyG0QijIrBLG","pycharm":{"name":"#%% md\n"}},"source":["### Train the LSTM\n","\n","Let's train the LSTM on a small amount of dummy text:"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"cvRAXqBUrBLH","pycharm":{"is_executing":true,"name":"#%%\n"},"executionInfo":{"status":"ok","timestamp":1649704057509,"user_tz":-120,"elapsed":357,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}}},"outputs":[],"source":["id_to_token, token_to_id, n_token, inp_text, out_text = get_data_lm(dummy_text)\n","X_train, X_test, y_train, y_test = train_test_split(inp_text, out_text, test_size=0.25, random_state=SEED)"]},{"cell_type":"markdown","metadata":{"id":"3XlUphKLrBLI","pycharm":{"name":"#%% md\n"}},"source":["Modify the training loop you defined for the elman RNN, and use it to train the LSTM model:"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"v-Wfh9swrBLJ","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649704080591,"user_tz":-120,"elapsed":21101,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"6c6722c7-72ac-48a9-f014-e3b38a45f0f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 1/100 iteration: 50 train-Loss: 0.0 val-loss: 6.407227993011475\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 3/100 iteration: 100 train-Loss: 0.0 val-loss: 6.181799411773682\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 5/100 iteration: 150 train-Loss: 0.0 val-loss: 6.017387866973877\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 7/100 iteration: 200 train-Loss: 0.0 val-loss: 5.939611911773682\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 9/100 iteration: 250 train-Loss: 0.0 val-loss: 5.910603046417236\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 11/100 iteration: 300 train-Loss: 0.0 val-loss: 5.943719387054443\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 12/100 iteration: 350 train-Loss: 0.0 val-loss: 5.957814693450928\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 14/100 iteration: 400 train-Loss: 0.0 val-loss: 5.9651055335998535\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 16/100 iteration: 450 train-Loss: 0.0 val-loss: 6.031222820281982\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 18/100 iteration: 500 train-Loss: 0.0 val-loss: 6.0866594314575195\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 20/100 iteration: 550 train-Loss: 0.0 val-loss: 6.152822494506836\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 22/100 iteration: 600 train-Loss: 0.0 val-loss: 6.213942527770996\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 24/100 iteration: 650 train-Loss: 0.0 val-loss: 6.244225978851318\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 25/100 iteration: 700 train-Loss: 0.0 val-loss: 6.324062824249268\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 27/100 iteration: 750 train-Loss: 0.0 val-loss: 6.380009651184082\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 29/100 iteration: 800 train-Loss: 0.0 val-loss: 6.439921855926514\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 31/100 iteration: 850 train-Loss: 0.0 val-loss: 6.517889022827148\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 33/100 iteration: 900 train-Loss: 0.0 val-loss: 6.568541526794434\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 35/100 iteration: 950 train-Loss: 0.0 val-loss: 6.696499347686768\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 37/100 iteration: 1000 train-Loss: 0.0 val-loss: 6.726792812347412\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 38/100 iteration: 1050 train-Loss: 0.0 val-loss: 6.763177394866943\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 40/100 iteration: 1100 train-Loss: 0.0 val-loss: 6.847410202026367\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 42/100 iteration: 1150 train-Loss: 0.0 val-loss: 6.927182674407959\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 44/100 iteration: 1200 train-Loss: 0.0 val-loss: 6.977327823638916\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 46/100 iteration: 1250 train-Loss: 0.0 val-loss: 7.023128986358643\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 48/100 iteration: 1300 train-Loss: 0.0 val-loss: 7.209463596343994\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 49/100 iteration: 1350 train-Loss: 0.0 val-loss: 7.134119510650635\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 51/100 iteration: 1400 train-Loss: 0.0 val-loss: 7.1810808181762695\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 53/100 iteration: 1450 train-Loss: 0.0 val-loss: 7.219418048858643\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 55/100 iteration: 1500 train-Loss: 0.0 val-loss: 7.306232452392578\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 57/100 iteration: 1550 train-Loss: 0.0 val-loss: 7.359488010406494\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 59/100 iteration: 1600 train-Loss: 0.0 val-loss: 7.400815010070801\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 61/100 iteration: 1650 train-Loss: 0.0 val-loss: 7.463265895843506\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 62/100 iteration: 1700 train-Loss: 0.0 val-loss: 7.523480415344238\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 64/100 iteration: 1750 train-Loss: 0.0 val-loss: 7.555262088775635\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 66/100 iteration: 1800 train-Loss: 0.0 val-loss: 7.56566047668457\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 68/100 iteration: 1850 train-Loss: 0.0 val-loss: 7.571077346801758\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 70/100 iteration: 1900 train-Loss: 0.0 val-loss: 7.642083168029785\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 72/100 iteration: 1950 train-Loss: 0.0 val-loss: 7.745882511138916\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 74/100 iteration: 2000 train-Loss: 0.0 val-loss: 7.890389442443848\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 75/100 iteration: 2050 train-Loss: 0.0 val-loss: 7.795958518981934\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 77/100 iteration: 2100 train-Loss: 0.0 val-loss: 7.85584831237793\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 79/100 iteration: 2150 train-Loss: 0.0 val-loss: 7.857122421264648\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 81/100 iteration: 2200 train-Loss: 0.0 val-loss: 7.871376991271973\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 83/100 iteration: 2250 train-Loss: 0.0 val-loss: 7.8963189125061035\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 85/100 iteration: 2300 train-Loss: 0.0 val-loss: 7.917490482330322\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 87/100 iteration: 2350 train-Loss: 0.0 val-loss: 7.985146999359131\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 88/100 iteration: 2400 train-Loss: 0.0 val-loss: 8.018260955810547\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 90/100 iteration: 2450 train-Loss: 0.0 val-loss: 8.037450790405273\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 92/100 iteration: 2500 train-Loss: 0.0 val-loss: 8.05926513671875\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 94/100 iteration: 2550 train-Loss: 0.0 val-loss: 8.095121383666992\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 96/100 iteration: 2600 train-Loss: 0.0 val-loss: 8.091277122497559\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 98/100 iteration: 2650 train-Loss: 0.0 val-loss: 8.184415817260742\n","torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","epoch: 99/100 iteration: 2700 train-Loss: 0.0 val-loss: 8.180000305175781\n"]}],"source":["net = LSTMLanguageModel(n_token, hidden_size)\n","net = net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters())\n","\n","iteration = 0\n","total_epochs = 100\n","\n","train_loss = 0\n","train_history = []\n","valid_history = []\n","\n","\n","for e in range(total_epochs):\n","    \n","    batches = get_batches(X_train, y_train, batch_size, seq_size)\n","    \n","    \n","    # 1) call zero_state\n","    # 2) put on the correct device\n","    # 3) loop through the data\n","    #     (See RNNLanguage model for the logic)\n","    \n","    ############### for student ################\n","    state_h,state_c = net.zero_state(batch_size,device)\n","    state_h = state_h.to(device)\n","    state_c = state_c.to(device)\n","    \n","    for x, y in batches:\n","\n","        iteration += 1\n","\n","        x = torch.tensor(x).to(device)\n","        y = torch.tensor(y).to(device)\n","        optimizer.zero_grad()\n","        logits, (hn,cn) = net(x, (state_h,state_c))\n","        loss = criterion(torch.transpose(logits,1,2), y)  \n","        loss.backward()           \n","        optimizer.step() \n","    ############################################\n","        \n","        if iteration % 50 == 0:\n","            train_loss = train_loss / 50.0\n","            val_loss = evaluate(device, net, n_token, 10, seq_size, X_test, y_test)\n","            \n","            train_history.append(train_loss)\n","            valid_history.append(val_loss)\n","            \n","            print('epoch: {}/{} iteration: {} train-Loss: {} val-loss: {}'.format(e, total_epochs, iteration, train_loss, val_loss))\n","            train_loss = 0"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"q0U4R8TZrBLK","pycharm":{"is_executing":true,"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649704089950,"user_tz":-120,"elapsed":278,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"ceeb89ea-151a-4471-faee-e7fd1fd533ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 10, 256])\n","torch.Size([1, 10, 256])\n","Good job! We're almost done..\n"]}],"source":["## evaluation\n","## DON'T CHANGE THIS CELL IN ANY WAY\n","\n","dummy_loss = evaluate(device, net, n_token, 10, 64, X_test, y_test)\n","\n","assert np.exp(dummy_loss) < 1e4, 'your dummy loss is too large!'\n","\n","print(\"Good job! We're almost done..\")"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"2pMIrFgvvLKe","pycharm":{"is_executing":true},"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1649704100713,"user_tz":-120,"elapsed":382,"user":{"displayName":"Louise Fan Chou","userId":"02530256663998508643"}},"outputId":"6369525e-8151-4fc9-bcfc-0bdd634c0262"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["epoch_count = range(1, len(train_history) + 1) \n","\n","# Visualize loss history\n","plt.plot(epoch_count, train_history, 'r--')\n","plt.plot(epoch_count, valid_history, 'b-')\n","plt.legend(['train', 'valid'])\n","plt.xlabel('iteration')\n","plt.ylabel('loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"C5eKXBlprBLM"},"source":["What we see on the plot above is known as __overfitting__: the training loss becomes really small towards the end of training, but the validation error of the model is high. This is due to the model learning “too much” from the training dataset, so that it does not generalize well to unseen data. You can probably guess why this happened? We are still training the model on a small subsample of the data (`dummy_text`)! If you train the model on the whole dataset, you will definitely get better validation scores. You can try this out if you want to, but be aware that training will likely take much longer. "]},{"cell_type":"markdown","metadata":{"id":"Q1AXRyKjC_15"},"source":["### Question 6\n","\n","Give at least 6 ideas on how you could make your neural language model better (short, bullet-style answers). (You can find inspiration online, for example here: https://arxiv.org/pdf/1708.02182.pdf) \n","\n","**<font color=blue><<< INSERT ANSWER HERE >>></font>**\n","\n","1.   collect more amount of data\n","2.   process data by using activiation functions\n","3.   feature selection\n","4.   data visualization to weed out abnormal values\n","5.   parameter tuning: weight initialization, learining rate, batch_size, epoch, activation function selection, numbers of hidden layers, regularization, \n","6.   algrithm optimization\n","7.   normalization\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"onSqaZNHJ7nI"},"source":["**If you would have a lot more time (not within the scope of this lab!)**: you've learned the building blocks of neural language models, you can now build the ultimate monster:\n","* Weight tying: Two weight matrices have been used for input or output respectively (https://arxiv.org/abs/1608.05859)\n","* Make it character-level or make use of sub-word units like [bpe](https://en.wikipedia.org/wiki/Byte_pair_encoding);\n","* Use both character-level and word-level features to train a word-level language model\n","* ..."]},{"cell_type":"markdown","metadata":{"id":"unVUS9vLrBLN"},"source":["### Question 7\n","\n","Please give us a rough estimation of the hours you invested to complete this session. This will not affect your grade ;) However, it might help us with the design of our future lab sessions. \n"," \n","**<font color=blue><<< Around 70 hours >>></font>**"]},{"cell_type":"markdown","metadata":{"id":"Omkl98XQrBLO"},"source":["## Acknowledgment\n","If you received help or feedback from fellow students, please acknowledge that here. We count on your academic honesty:\n","\n","**<font color=blue><<< INSERT ANSWER HERE >>></font>**\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["-nTsCEeCrBJv","vEPXFNpVrBJ3","1lS9tYi3rBKA","unVUS9vLrBLN","Omkl98XQrBLO"],"name":"NLP_lab2_student.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}